{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd.functional import jacobian as J\n",
    "from torch.autograd import Function\n",
    "import torch.utils.benchmark as benchmark\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from path import Path\n",
    "import glob\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from scipy.stats import bootstrap\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import copy\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch_tps import ThinPlateSpline\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "\n",
    "# data folder\n",
    "cloud = Path(\"\") #fill in folder for saves\n",
    "D, H, W = 100,100,100 #depth, height, width for discretization\n",
    "\n",
    "#ModelNet (http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip)\n",
    "path = Path(\"\") #fill in location of ModelNet\n",
    "\n",
    "# misc\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# keypoints / graph\n",
    "k = 10 #neighbours fixed\n",
    "k1 = 128 #neighbours moving\n",
    "\n",
    "# displacement space for dLBP\n",
    "l_max = 9\n",
    "l_width = l_max * 2 + 1\n",
    "q = 3\n",
    "disp = torch.stack(torch.meshgrid(torch.arange(- q * l_max, q * l_max + 1, q),\n",
    "                                  torch.arange(- q * l_max, q * l_max + 1, q),\n",
    "                                  torch.arange(- q * l_max, q * l_max + 1, q))).permute(1, 2, 3, 0).contiguous().view(1, -1, 3).float()\n",
    "disp = (disp.flip(-1) * 2 / (torch.tensor([W, H, D]) - 1)).to(device)\n",
    "\n",
    "#sLBP\n",
    "slbp_iter = 3\n",
    "slbp_cost_scale = 10 #should not be needed due to newly introduced automatic scaler\n",
    "slbp_alpha = -50 #regularization\n",
    "\n",
    "#dLBP\n",
    "dlbp_iter = 5\n",
    "dlbp_cost_scale = 1\n",
    "dlbp_alpha = -50#-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loopy Belief Propagation-----------------------------------------------------------------------------------------------------------------------------------\n",
    "#based on https://github.com/multimodallearning/deep-geo-reg\n",
    "\n",
    "def pdist(x, p=2):\n",
    "    if p==1:\n",
    "        dist = torch.abs(x.unsqueeze(2) - x.unsqueeze(1)).sum(dim=2)\n",
    "    elif p==2:\n",
    "        xx = (x**2).sum(dim=2).unsqueeze(2)\n",
    "        yy = xx.permute(0, 2, 1)\n",
    "        dist = xx + yy - 2.0 * torch.bmm(x, x.permute(0, 2, 1))\n",
    "        dist[:, torch.arange(dist.shape[1]), torch.arange(dist.shape[2])] = 0\n",
    "    return dist\n",
    "\n",
    "def pdist2(x, y, p=2):\n",
    "    if p==1:\n",
    "        dist = torch.abs(x.unsqueeze(2) - y.unsqueeze(1)).sum(dim=3)\n",
    "    elif p==2:\n",
    "        xx = (x**2).sum(dim=2).unsqueeze(2)\n",
    "        yy = (y**2).sum(dim=2).unsqueeze(1)\n",
    "        dist = xx + yy - 2.0 * torch.bmm(x, y.permute(0, 2, 1))\n",
    "    return dist\n",
    "\n",
    "def knn_graph(kpts, k, include_self=False):\n",
    "    B, N, D = kpts.shape\n",
    "    device = kpts.device\n",
    "    \n",
    "    dist = pdist(kpts)\n",
    "    ind = (-dist).topk(k + (1 - int(include_self)), dim=-1)[1][:, :, 1 - int(include_self):]\n",
    "    A = torch.zeros(B, N, N).to(device)\n",
    "    A[:, torch.arange(N).repeat(k), ind[0].t().contiguous().view(-1)] = 1\n",
    "    A[:, ind[0].t().contiguous().view(-1), torch.arange(N).repeat(k)] = 1\n",
    "    \n",
    "    return ind, dist*A, A\n",
    "\n",
    "def lbp_graph(kpts_fixed):\n",
    "    A = knn_graph(kpts_fixed, k, include_self=False)[2][0]\n",
    "    edges = A.nonzero()\n",
    "    edges_idx = torch.zeros_like(A).long()\n",
    "    edges_idx[A.bool()] = torch.arange(edges.shape[0]).to(device)\n",
    "    edges_reverse_idx = edges_idx.t()[A.bool()]\n",
    "    return edges, edges_reverse_idx\n",
    "\n",
    "def inference(kpts_fixed, kpts_moving,kpts_fixed_feat,kpts_moving_feat, f=1):\n",
    "    N_p_fixed = kpts_fixed.shape[1]\n",
    "    if f:    \n",
    "        dist = pdist2(kpts_fixed_feat, kpts_moving_feat)\n",
    "    else:\n",
    "        dist = pdist2(kpts_fixed, kpts_moving)\n",
    "    ind = (-dist).topk(k1, dim=-1)[1]\n",
    "    candidates = - kpts_fixed.view(1, N_p_fixed, 1, 3) + kpts_moving[:, ind.view(-1), :].view(1, N_p_fixed, k1, 3)\n",
    "    candidates_cost = (kpts_fixed_feat.view(1, N_p_fixed, 1, -1) - kpts_moving_feat[:, ind.view(-1), :].view(1, N_p_fixed, k1, -1)).pow(2).mean(3)\n",
    "    edges, edges_reverse_idx = lbp_graph(kpts_fixed)\n",
    "    messages = torch.zeros((edges.shape[0], k1)).to(device)\n",
    "    candidates_edges0 = candidates[0, edges[:, 0], :, :]\n",
    "    candidates_edges1 = candidates[0, edges[:, 1], :, :]\n",
    "    for _ in range(slbp_iter):\n",
    "        temp_message = torch.zeros((N_p_fixed, k1)).to(device).scatter_add_(0, edges[:, 1].view(-1, 1).expand(-1, k1), messages)\n",
    "        multi_data_cost = torch.gather(temp_message + candidates_cost.squeeze(), 0, edges[:,0].view(-1, 1).expand(-1, k1))\n",
    "        reverse_messages = torch.gather(messages, 0, edges_reverse_idx.view(-1, 1).expand(-1, k1))\n",
    "        multi_data_cost -= reverse_messages\n",
    "        messages = torch.zeros_like(multi_data_cost)\n",
    "        unroll_factor = 32\n",
    "        split = torch.chunk(torch.arange(multi_data_cost.shape[0]), unroll_factor)\n",
    "        for i in range(unroll_factor):\n",
    "            messages[split[i]] = torch.min(multi_data_cost[split[i]].unsqueeze(1) + slbp_cost_scale*(candidates_edges0[split[i]].unsqueeze(1) - candidates_edges1[split[i]].unsqueeze(2)).pow(2).sum(3), 2)[0]\n",
    "    reg_candidates_cost = (temp_message + candidates_cost.view(-1, k1)).unsqueeze(0)\n",
    "    sm = F.softmax(slbp_alpha * reg_candidates_cost.view(1, N_p_fixed, -1), 2).unsqueeze(3)\n",
    "    kpts_fixed_disp_pred = (candidates * sm).sum(2)\n",
    "    return kpts_fixed_disp_pred\n",
    "\n",
    "#For discrete LBP\n",
    "def minconv(input, l_width):\n",
    "    disp1d = torch.linspace(-1,1,l_width).to(input.device)\n",
    "    regular1d = (disp1d.reshape(1,-1) - disp1d.reshape(-1,1)) ** 2\n",
    "    \n",
    "    output = torch.min( input.view(-1, l_width, 1, l_width, l_width) + regular1d.view(1, l_width, l_width, 1, 1), 1)[0]\n",
    "    output = torch.min(output.view(-1, l_width, l_width, 1, l_width) + regular1d.view(1, 1, l_width, l_width, 1), 2)[0]\n",
    "    output = torch.min(output.view(-1, l_width, l_width, l_width, 1) + regular1d.view(1, 1, 1, l_width, l_width), 3)[0]\n",
    "\n",
    "    output = output - (torch.min(output.view(-1, l_width ** 3), 1)[0]).view(output.shape[0], 1, 1, 1)\n",
    "\n",
    "    return output.view_as(input)\n",
    "\n",
    "class InverseGridSample(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input, grid, shape, mode='bilinear', padding_mode='zeros', align_corners=None):\n",
    "        B, C, N = input.shape\n",
    "        D = grid.shape[-1]\n",
    "        device = input.device\n",
    "        dtype = input.dtype\n",
    "        \n",
    "        ctx.save_for_backward(input, grid)\n",
    "        \n",
    "        if D == 2:\n",
    "            input_view = [B, C, -1, 1]\n",
    "            grid_view = [B, -1, 1, 2]\n",
    "        elif D == 3:\n",
    "            input_view = [B, C, -1, 1, 1]\n",
    "            grid_view = [B, -1, 1, 1, 3]\n",
    "            \n",
    "        ctx.grid_view = grid_view\n",
    "        ctx.mode = mode\n",
    "        ctx.padding_mode = padding_mode\n",
    "        ctx.align_corners = align_corners\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            output = J(lambda x: InverseGridSample.sample(input.view(*input_view), grid.view(*grid_view), x, mode, padding_mode, align_corners), (torch.zeros(B, C, *shape).to(dtype).to(device)))\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):        \n",
    "        input, grid = ctx.saved_tensors\n",
    "        grid_view = ctx.grid_view\n",
    "        mode = ctx.mode\n",
    "        padding_mode = ctx.padding_mode\n",
    "        align_corners = ctx.align_corners\n",
    "        \n",
    "        grad_input = F.grid_sample(grad_output, grid.view(*grid_view), mode, padding_mode, align_corners)\n",
    "        \n",
    "        return grad_input.view(*input.shape), None, None, None, None, None\n",
    "        \n",
    "    @staticmethod\n",
    "    def sample(input, grid, accu, mode='bilinear', padding_mode='zeros', align_corners=None):\n",
    "        sampled = F.grid_sample(accu, grid, mode, padding_mode, align_corners)\n",
    "        return -0.5 * ((input - sampled) ** 2).sum()\n",
    "    \n",
    "def inverse_grid_sample(input, grid, shape, mode='bilinear', padding_mode='zeros', align_corners=None):\n",
    "    return InverseGridSample.apply(input, grid, shape, mode, padding_mode, align_corners)\n",
    "\n",
    "def discretize(kpts_fixed, kpts_fixed_feat, kpts_moving, kpts_moving_feat, f=1):\n",
    "    N_p_fixed = kpts_fixed.shape[1]\n",
    "    disp_range = disp.max(1, keepdim=True)[0]\n",
    "    if f:\n",
    "        dist = pdist2(kpts_fixed_feat, kpts_moving_feat)\n",
    "    else:\n",
    "        dist = pdist2(kpts_fixed, kpts_moving)\n",
    "    ind = (-dist).topk(k1, dim=-1)[1]\n",
    "    candidates = - kpts_fixed.view(1, N_p_fixed, 1, 3) + kpts_moving[:, ind.view(-1), :].view(1, N_p_fixed, k1, 3)\n",
    "    candidates_cost = (kpts_fixed_feat.view(1, N_p_fixed, 1, -1) - kpts_moving_feat[:, ind.view(-1), :].view(1, N_p_fixed, k1, -1)).pow(2).mean(3, keepdim=True)\n",
    "    grid = inverse_grid_sample(candidates_cost.view(N_p_fixed, 1, -1), candidates[0]/disp_range, (l_width, l_width, l_width), mode='nearest', padding_mode='zeros', align_corners=True)\n",
    "    grid_norm = inverse_grid_sample(torch.ones_like(candidates_cost.view(N_p_fixed, 1, -1)), candidates[0]/disp_range, (l_width, l_width, l_width), mode='nearest', padding_mode='zeros', align_corners=True)\n",
    "    cost = grid  / (grid_norm + 0.000001)\n",
    "    cost[cost==0] = 1e4\n",
    "    return cost\n",
    "\n",
    "#Wrapper smooth or discrete, new candidate search in feature space or old in 3D Euclidean space\n",
    "\n",
    "def sLBP_GF(kpts_fixed, kpts_moving, net, f=1):\n",
    "    # geometric features\n",
    "    kpts_fixed_feat, kpts_moving_feat = net(kpts_fixed, kpts_moving, k)\n",
    "    kpts_fixed_disp_pred = inference(kpts_fixed,kpts_moving,kpts_fixed_feat,kpts_moving_feat, f)\n",
    "    return kpts_fixed_disp_pred\n",
    "\n",
    "def sLBP_GF_old(kpts_fixed, kpts_moving, net):\n",
    "    return sLBP_GF(kpts_fixed, kpts_moving, net, f=0)\n",
    "\n",
    "def dLBP_GF(kpts_fixed, kpts_moving, net, f=1):\n",
    "    N_p_fixed = kpts_fixed.shape[1]\n",
    "\n",
    "    # geometric features\n",
    "    kpts_fixed_feat, kpts_moving_feat = net(kpts_fixed, kpts_moving, k)\n",
    "\n",
    "    # match\n",
    "    cost = discretize(kpts_fixed, kpts_fixed_feat, kpts_moving, kpts_moving_feat, f)\n",
    "    edges, _ = lbp_graph(kpts_fixed)\n",
    "    messages = torch.zeros_like(cost)\n",
    "    for _ in range(dlbp_iter):\n",
    "        message_data = messages + cost\n",
    "        reg_message_data = minconv(dlbp_cost_scale*message_data, l_width)/dlbp_cost_scale\n",
    "        messages = torch.zeros_like(cost).view(N_p_fixed, -1).scatter_add_(0, edges[:, 0].view(-1, 1).expand(-1, l_width**3), reg_message_data[edges[:, 1]].view(-1, l_width**3)).view_as(cost)        \n",
    "    reg_cost = messages + cost\n",
    "    kpts_fixed_disp_pred = (disp.unsqueeze(1) * F.softmax(dlbp_alpha * reg_cost.view(1, N_p_fixed, -1), 2).unsqueeze(3)).sum(2)  \n",
    "    return kpts_fixed_disp_pred\n",
    "\n",
    "def dLBP_GF_old(kpts_fixed, kpts_moving, net):\n",
    "    return dLBP_GF(kpts_fixed, kpts_moving, net, f=0)\n",
    "\n",
    "#NETWORK ARCHITECTURES-----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "class EdgeConv(nn.Module):\n",
    "    #based on https://github.com/multimodallearning/deep-geo-reg\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EdgeConv, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*2, out_channels, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, 1, bias=False),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, ind):\n",
    "        B, N, D = x.shape\n",
    "        k = ind.shape[2]\n",
    "\n",
    "        y = x.reshape(B*N, D)[ind.reshape(B*N, k)].reshape(B, N, k, D)\n",
    "        x = x.reshape(B, N, 1, D).expand(B, N, k, D)\n",
    "        \n",
    "        x = torch.cat([y - x, x], dim=3)\n",
    "        \n",
    "        x = self.conv(x.permute(0, 3, 1, 2))\n",
    "        x = F.max_pool2d(x, (1, k))\n",
    "        x = x.squeeze(3).permute(0, 2, 1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Tnet(nn.Module):\n",
    "   #based on https://gist.github.com/nikitakaraevv/d5047c9374c2fe6c9e6251886df00cdb\n",
    "   def __init__(self, k=3):\n",
    "        super().__init__()\n",
    "        self.k=k\n",
    "        self.conv1 = nn.Conv1d(k,64,1)\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,k*k)\n",
    "    \n",
    "        self.bn1 = nn.InstanceNorm1d(64)\n",
    "        self.bn2 = nn.InstanceNorm1d(128)\n",
    "        self.bn3 = nn.InstanceNorm1d(1024)\n",
    "        self.bn4 = nn.InstanceNorm1d(512)\n",
    "        self.bn5 = nn.InstanceNorm1d(256)\n",
    "\n",
    "   def forward(self, input):\n",
    "        # input.shape ==  bs,3,n\n",
    "        bs = input.size(0)\n",
    "        xb = F.relu(self.bn1(self.conv1(input)))\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "        pool_size = int(xb.size(-1))\n",
    "        pool = F.max_pool1d(xb, pool_size).squeeze(-1)\n",
    "        flat = nn.Flatten(1)(pool)\n",
    "        xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "        xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "        #initialize as identity\n",
    "        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "        if xb.is_cuda:\n",
    "            init=init.cuda()\n",
    "        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "        return matrix\n",
    "   \n",
    "   \n",
    "#Feature Descriptor Networks------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "class TGraphNet(nn.Module):\n",
    "    \"\"\"\n",
    "    T-GraphNet\n",
    "    \"\"\"\n",
    "    def __init__(self, D = 3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_transform = Tnet(k=D)\n",
    "        \n",
    "        self.conv1 = EdgeConv(D, 32)\n",
    "        self.conv2 = EdgeConv(32, 32)\n",
    "        self.conv3 = EdgeConv(32, 64)\n",
    "\n",
    "        self.conv4  = nn.Sequential(nn.Conv1d(64, 64, 1, bias=False),\n",
    "                                    nn.InstanceNorm1d(64),\n",
    "                                    nn.Conv1d(64, 64, 1))\n",
    " \n",
    "    def forward(self, x, y, k):\n",
    "        #Apply T-Net\n",
    "        matrix3x3x = self.input_transform(x.transpose(1,2)) \n",
    "        x = torch.bmm(x, matrix3x3x)\n",
    "\n",
    "        matrix3x3y = self.input_transform(y.transpose(1,2)) \n",
    "        y = torch.bmm(y, matrix3x3y)   \n",
    "\n",
    "        #Apply EdgeConv\n",
    "        fixed_ind = knn_graph(x, k, include_self=True)[0]\n",
    "        x = self.conv1(x, fixed_ind)\n",
    "        x = self.conv2(x, fixed_ind)\n",
    "        x = self.conv3(x, fixed_ind)\n",
    "        \n",
    "        moving_ind = knn_graph(y, k*3, include_self=True)[0]\n",
    "        y = self.conv1(y, moving_ind)\n",
    "        y = self.conv2(y, moving_ind)\n",
    "        y = self.conv3(y, moving_ind)\n",
    "\n",
    "        #Apply MLP\n",
    "        x = self.conv4(x.permute(0,2,1)).permute(0,2,1)\n",
    "        y = self.conv4(y.permute(0,2,1)).permute(0,2,1)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "#Loss function\n",
    "def netloss(disp, disp_pred):\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    return criterion(disp, disp_pred)\n",
    "\n",
    "#ModelNet-----------------------------------------------------------------------------------------------------------------------------------\n",
    "def read_off(file):\n",
    "    #https://gist.github.com/nikitakaraevv/3b95c0f39448951c431761c054dbc3fc\n",
    "    if 'OFF' != file.readline().strip():\n",
    "        raise('Not a valid OFF header')\n",
    "    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
    "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "    return verts, faces\n",
    "    \n",
    "class PointSampler(object):\n",
    "    #https://colab.research.google.com/github/nikitakaraevv/pointnet/blob/master/nbs/PointNetClass.ipynb\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def triangle_area(self, pt1, pt2, pt3):\n",
    "        side_a = np.linalg.norm(pt1 - pt2)\n",
    "        side_b = np.linalg.norm(pt2 - pt3)\n",
    "        side_c = np.linalg.norm(pt3 - pt1)\n",
    "        s = 0.5 * ( side_a + side_b + side_c)\n",
    "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
    "\n",
    "    def sample_point(self, pt1, pt2, pt3):\n",
    "        # barycentric coordinates on a triangle\n",
    "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
    "        s, t = sorted([random.random(), random.random()])\n",
    "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
    "        return (f(0), f(1), f(2))\n",
    "        \n",
    "    \n",
    "    def __call__(self, mesh):\n",
    "        verts, faces, def_lvl, typ_nr, setting, rotation = mesh\n",
    "        verts = np.array(verts)\n",
    "        areas = np.zeros((len(faces)))\n",
    "\n",
    "        for i in range(len(areas)):\n",
    "            areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
    "                                           verts[faces[i][1]],\n",
    "                                           verts[faces[i][2]]))\n",
    "            \n",
    "        sampled_faces = (random.choices(faces, \n",
    "                                      weights=areas,\n",
    "                                      cum_weights=None,\n",
    "                                      k=self.output_size))\n",
    "        \n",
    "        sampled_points = np.zeros((self.output_size, 3))\n",
    "\n",
    "        for i in range(len(sampled_faces)):\n",
    "            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
    "                                                   verts[sampled_faces[i][1]],\n",
    "                                                   verts[sampled_faces[i][2]]))\n",
    "        \n",
    "        return (sampled_points, def_lvl, typ_nr, setting, rotation)\n",
    "\n",
    "class Normalize_ModelNet(object):\n",
    "    def __call__(self, inp):\n",
    "        pointcloud, def_lvl, typ_nr, setting, rotation = inp\n",
    "        assert len(pointcloud.shape)==2\n",
    "        \n",
    "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
    "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "        return  (norm_pointcloud, def_lvl, typ_nr, setting, rotation)\n",
    "\n",
    "class TPS(object):\n",
    "    \"\"\"Perform Thin Plate Spline deformation\"\"\"\n",
    "    def __init__(self, enabled=True, resolution = 5, alpha = 0.5):\n",
    "        self.enabled = enabled\n",
    "        self.tps = ThinPlateSpline(alpha)\n",
    "        xs = torch.linspace(-1, 1, steps=resolution)\n",
    "        ys = torch.linspace(-1, 1, steps=resolution)\n",
    "        zs = torch.linspace(-1, 1, steps=resolution)\n",
    "        x, y, z = torch.meshgrid(xs, ys, zs, indexing='xy')\n",
    "        self.xyz = torch.stack([x, y, z], dim=3).reshape(-1, 3)\n",
    "        \n",
    "    def fit(self,pc, def_lvl):\n",
    "        #noise = (torch.rand(self.xyz.shape)-0.5)*2*def_lvl #change back for uniform instead of gaussian\n",
    "        self.tps.fit(self.xyz, torch.normal(self.xyz,def_lvl))#self.xyz+noise)\n",
    "        transformed_pc = self.tps.transform(pc) \n",
    "        return transformed_pc\n",
    "\n",
    "    def __call__(self, inp): \n",
    "        source, def_lvl, typ_nr, setting, rotation = inp\n",
    "        source = torch.from_numpy(source).float()\n",
    "        if not self.enabled: return (source, source.clone(), typ_nr, setting, rotation)\n",
    "        target = self.fit(source, def_lvl) \n",
    "        return (source, target, typ_nr, setting, rotation)\n",
    "\n",
    "class RandRotation_z(object):\n",
    "    def __init__(self, enabled=True):\n",
    "        self.enabled = enabled\n",
    "    def __call__(self, inp):\n",
    "        if not self.enabled: return inp[0], inp[1]\n",
    "        rotation = inp[2]\n",
    "        return (inp[0], self.rotate(inp[1].float(), rotation))\n",
    "\n",
    "    def rotate(self, pointcloud, rotation):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        rot_matrix = _axis_angle_rotation('Z',torch.tensor(rotation))\n",
    "        rot_pointcloud = torch.mm(rot_matrix.double(),pointcloud.double().T).T\n",
    "        return  rot_pointcloud\n",
    "\n",
    "def _axis_angle_rotation(axis: str, angle: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Return the rotation matrices for one of the rotations about an axis\n",
    "    of which Euler angles describe, for each value of the angle given.\n",
    "    https://pytorch3d.readthedocs.io/en/latest/_modules/pytorch3d/transforms/rotation_conversions.html\n",
    "    Args:\n",
    "        axis: Axis label \"X\" or \"Y or \"Z\".\n",
    "        angle: any shape tensor of Euler angles in radians\n",
    "    Returns:\n",
    "        Rotation matrices as tensor of shape (..., 3, 3).\n",
    "    \"\"\"\n",
    "\n",
    "    cos = torch.cos(angle)\n",
    "    sin = torch.sin(angle)\n",
    "    one = torch.ones_like(angle)\n",
    "    zero = torch.zeros_like(angle)\n",
    "\n",
    "    if axis == \"X\":\n",
    "        R_flat = (one, zero, zero, zero, cos, -sin, zero, sin, cos)\n",
    "    elif axis == \"Y\":\n",
    "        R_flat = (cos, zero, sin, zero, one, zero, -sin, zero, cos)\n",
    "    elif axis == \"Z\":\n",
    "        R_flat = (cos, -sin, zero, sin, cos, zero, zero, zero, one)\n",
    "    else:\n",
    "        raise ValueError(\"letter must be either X, Y or Z.\")\n",
    "\n",
    "    return torch.stack(R_flat, -1).reshape(angle.shape + (3, 3))\n",
    "   \n",
    "class Modify(object):   \n",
    "    \"\"\"\n",
    "    Add Incompleteness, Noise or Outliers to pointcloud.\n",
    "    \"\"\"\n",
    "    def __call__(self, inp):\n",
    "        source, target, typ_nr, setting, rotation = inp\n",
    "        if typ_nr == 0:\n",
    "            return source, target, rotation\n",
    "        elif typ_nr == 1:\n",
    "            return self.incomp(source,setting), target, rotation\n",
    "        elif typ_nr == 2:\n",
    "            return source, self.nois(target,setting), rotation\n",
    "        elif typ_nr == 3:\n",
    "            return source, self.out(target,setting), rotation\n",
    "        \n",
    "    def incomp(self, pointcloud, setting):\n",
    "        dist = torch.norm(pointcloud - pointcloud[int(torch.rand((1))*len(pointcloud))], dim=1, p=None)\n",
    "        knn = dist.topk(int(len(pointcloud)*(1-setting/100)))\n",
    "        return pointcloud[knn.indices], knn.indices\n",
    "\n",
    "    def nois(self, pointcloud, noise_lvl):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        #noise = (torch.rand(pointcloud.shape)-0.5)*2*noise_lvl #change back for uniform instead of gaussian\n",
    "        noisy_pointcloud = torch.normal(pointcloud,noise_lvl) #+ noise\n",
    "        return  noisy_pointcloud\n",
    "\n",
    "    def out(self, pointcloud, setting):\n",
    "        dims = pointcloud.shape\n",
    "        outliers = (torch.rand((int(dims[0]*setting/100), dims[1]))-0.5)*2\n",
    "        return torch.cat((pointcloud, outliers), 0)\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, inp):\n",
    "        source_pointcloud, target_pointcloud = inp[0], inp[1]\n",
    "        assert len(source_pointcloud.shape)==2\n",
    "\n",
    "        return torch.from_numpy(source_pointcloud), torch.from_numpy(target_pointcloud)#, inp[2], inp[3]\n",
    "    \n",
    "class PointCloudData_ModelNet(Dataset):\n",
    "    def __init__(self, root_dir, transform, folder=\"train\", typ = [\"Deformation_Level\"], rotation = 1/8):\n",
    "        \"\"\"\n",
    "        Class for ModelNet dataset.\n",
    "\n",
    "        IN:\n",
    "        root_dir : str\n",
    "            ModelNet folder.\n",
    "        transform : transform\n",
    "            Transforms to apply to data\n",
    "        folder : \"train\" or \"test\"\n",
    "            Load train or test data\n",
    "        typ : str \"Deformation_Level\" or \"Incompleteness_Data\" or \"Noisy_Data\" or \"Outlier_Data\"\n",
    "            Different types of challenges to process\n",
    "        rotation : float in [0,1]\n",
    "            Percentage of complete rotation around z-axis\n",
    "            \n",
    "        OUT:\n",
    "        Dataset class object\n",
    "        \"\"\"\n",
    "\n",
    "        random.seed(42)\n",
    "        self.root_dir = root_dir\n",
    "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "        self.transforms = transform\n",
    "        self.files = []\n",
    "        self.types_nr_dict= {\"Deformation_Level\":0,\"Incompleteness_Data\":1,\"Noisy_Data\":2,\"Outlier_Data\":3}\n",
    "        self.settings =[[0],[0,5,10,15,20,25],[0,0.01,0.02,0.03,0.04],[0,5,15,25,35,45]]\n",
    "        for category in self.classes.keys():\n",
    "            new_dir = root_dir/Path(category)/folder\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith('.off'):   \n",
    "                    if len(typ)>1:\n",
    "                        typ_nrs=[]\n",
    "                        for t in typ:\n",
    "                            typ_nrs.append(self.types_nr_dict[t])\n",
    "                        choice = np.random.randint(0,len(typ_nrs))\n",
    "                        typ_nr = typ_nrs[choice]\n",
    "                        typ_name = typ[choice]\n",
    "                    else:\n",
    "                        typ_nr = self.types_nr_dict[typ[0]]\n",
    "                        typ_name = typ[0]\n",
    "                    sample = {}\n",
    "                    sample['pcd_path'] = new_dir/file\n",
    "                    sample['category'] = category\n",
    "                    sample['name'] = file\n",
    "                    sample['def_lvl'] = random.randrange(1,10,1)/20 #random.randrange(1,10,1)/10 for unifrom deformation\n",
    "                    sample['type'] = typ_name\n",
    "                    sample['type_nr'] = typ_nr\n",
    "                    sample['setting'] = self.settings[typ_nr][random.randrange(0,len(self.settings[typ_nr]),1)]\n",
    "                    sample['rotation'] = np.around(random.random()*np.pi*2.*rotation,1)\n",
    "                    self.files.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __preproc__(self, file, def_lvl, typ_nr, setting, rotation):\n",
    "        \"\"\"\n",
    "        This is a helper method that preprocesses a file. \n",
    "        It reads the vertices and faces from an OFF file using the read_off() function, and applies the provided transformations (self.transforms) to the data. \n",
    "        It returns the preprocessed source and target point clouds.\n",
    "        \"\"\"\n",
    "        verts, faces = read_off(file)\n",
    "        if self.transforms:\n",
    "            source, target = self.transforms((verts, faces, def_lvl, typ_nr, setting, rotation))\n",
    "        return source, target\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        This method is called to retrieve an item from the dataset at the given index.\n",
    "        It retrieves the file path, category, name, deformation level, type, setting, and rotation for the specified index. \n",
    "        Then, it opens the point cloud file using open() and passes it to the __preproc__ method for preprocessing.\n",
    "        Depending on the typ_nr value, it determines the valid indices and calculates the displacement (disp).\n",
    "        Finally, it returns a dictionary containing the relevant data for the item.\n",
    "        \"\"\"\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        category = self.files[idx]['category']\n",
    "        name = self.files[idx]['name']\n",
    "        def_lvl = self.files[idx]['def_lvl']\n",
    "        typ = self.files[idx]['type']\n",
    "        typ_nr =  self.files[idx]['type_nr']\n",
    "        setting = self.files[idx]['setting']\n",
    "        rotation = self.files[idx]['rotation']\n",
    "        with open(pcd_path, 'r') as f:\n",
    "            source, target = self.__preproc__(f, def_lvl, typ_nr, setting, rotation)\n",
    "        if typ_nr == 1:\n",
    "            valid_ind=source[1]\n",
    "            source = source[0]\n",
    "            disp = target[valid_ind]-source\n",
    "        else:\n",
    "            disp = target[:source.shape[0]]-source \n",
    "            valid_ind=np.arange(0,len(source),1)\n",
    "        return {'source_pointcloud': source, \n",
    "                'target_pointcloud': target,\n",
    "                'disp': disp,\n",
    "                'category': self.classes[category],\n",
    "                'name': name,\n",
    "                'deformation' : def_lvl,\n",
    "                'type':typ,\n",
    "                'setting':setting,\n",
    "                'valid_ind' : valid_ind,\n",
    "                'rotation' : rotation}\n",
    "\n",
    "#Chamfer Distance-------------------------------------------------------------------------------------------------------------\n",
    "def chamfer_distance_without_batch(p1, p2, debug=False):\n",
    "\n",
    "    '''\n",
    "    Calculate Chamfer Distance between two point sets\n",
    "    https://gist.github.com/WangZixuan/4c4cdf49ce9989175e94524afc946726\n",
    "    :param p1: size[1, N, D]\n",
    "    :param p2: size[1, M, D]\n",
    "    :param debug: whether need to output debug info\n",
    "    :return: sum of Chamfer Distance of two point sets\n",
    "    '''\n",
    "\n",
    "    assert p1.size(0) == 1 and p2.size(0) == 1\n",
    "    assert p1.size(2) == p2.size(2)\n",
    "\n",
    "    if debug:\n",
    "        print(p1[0][0])\n",
    "\n",
    "    p1 = p1.repeat(p2.size(1), 1, 1)\n",
    "    if debug:\n",
    "        print('p1 size is {}'.format(p1.size()))\n",
    "\n",
    "    p1 = p1.transpose(0, 1)\n",
    "    if debug:\n",
    "        print('p1 size is {}'.format(p1.size()))\n",
    "        print(p1[0])\n",
    "\n",
    "    p2 = p2.repeat(p1.size(0), 1, 1)\n",
    "    if debug:\n",
    "        print('p2 size is {}'.format(p2.size()))\n",
    "        print(p2[0])\n",
    "\n",
    "    dist = torch.add(p1, torch.neg(p2))\n",
    "    if debug:\n",
    "        print('dist size is {}'.format(dist.size()))\n",
    "        print(dist[0])\n",
    "\n",
    "    dist = torch.norm(dist, 2, dim=2)\n",
    "    if debug:\n",
    "        print('dist size is {}'.format(dist.size()))\n",
    "        print(dist)\n",
    "\n",
    "    dist = torch.min(dist, dim=1)[0]\n",
    "    if debug:\n",
    "        print('dist size is {}'.format(dist.size()))\n",
    "        print(dist)\n",
    "\n",
    "    length = len(dist)\n",
    "\n",
    "    dist = torch.sum(dist)\n",
    "    if debug:\n",
    "        print('-------')\n",
    "        print(dist)\n",
    "\n",
    "    return dist/length #Right?\n",
    "\n",
    "\n",
    "#3D Plotting-----------------------------------------------------------------------------------------------------------------------------------\n",
    "def visualize_rotate(data):\n",
    "    #https://gist.github.com/nikitakaraevv/295f123c4f3cbecd734398eb9055fae1\n",
    "    x_eye, y_eye, z_eye = 1.25, 1.25, 0.8\n",
    "    frames=[]\n",
    "\n",
    "    def rotate_z(x, y, z, theta):\n",
    "        w = x+1j*y\n",
    "        return np.real(np.exp(1j*theta)*w), np.imag(np.exp(1j*theta)*w), z\n",
    "\n",
    "    for t in np.arange(0, 10.26, 0.1):\n",
    "        xe, ye, ze = rotate_z(x_eye, y_eye, z_eye, -t)\n",
    "        frames.append(dict(layout=dict(scene=dict(camera=dict(eye=dict(x=xe, y=ye, z=ze))))))\n",
    "    fig = go.Figure(data=data,\n",
    "                    layout=go.Layout(\n",
    "                        updatemenus=[dict(type='buttons',\n",
    "                                    showactive=False,\n",
    "                                    y=1,\n",
    "                                    x=0.8,\n",
    "                                    xanchor='left',\n",
    "                                    yanchor='bottom',\n",
    "                                    pad=dict(t=45, r=10),\n",
    "                                    buttons=[dict(label='Play',\n",
    "                                                    method='animate',\n",
    "                                                    args=[None, dict(frame=dict(duration=50, redraw=True),\n",
    "                                                                    transition=dict(duration=0),\n",
    "                                                                    fromcurrent=True,\n",
    "                                                                    mode='immediate'\n",
    "                                                                    )]\n",
    "                                                    )\n",
    "                                            ]\n",
    "                                    )\n",
    "                                ]\n",
    "                    ),\n",
    "                    frames=frames\n",
    "            )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def pcshow(source, target, reg, err_source, err_target, err_reg):\n",
    "    data=[go.Scatter3d(x=source[:,0], y=source[:,1], z=source[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_source)),\n",
    "            go.Scatter3d(x=target[:,0],y=target[:,1], z=target[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_target)),\n",
    "            go.Scatter3d(x=reg[:,0], y=reg[:,1], z=reg[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_reg)),\n",
    "            go.Scatter3d(x=target[:,0],y=target[:,1], z=target[:,2],\n",
    "                                   mode='markers',marker=dict(size=2,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=\"lime\", opacity=0.8))]\n",
    "    fig = visualize_rotate(data)\n",
    "    metric_figure = make_subplots(\n",
    "        rows=1, cols=3, row_titles=[\"Mean distance color encoded\"] ,subplot_titles=[\"Source\", \"Target\", \"Registered on target\"],\n",
    "        specs=[[{\"type\":\"scene\"}, {\"type\":\"scene\"}, {\"type\":\"scene\"}]])\n",
    "\n",
    "    metric_figure.append_trace(fig.data[0], row=1, col=1)\n",
    "    metric_figure.append_trace(fig.data[1], row=1, col=2)\n",
    "    metric_figure.append_trace(fig.data[2], row=1, col=3)\n",
    "    metric_figure.append_trace(fig.data[3], row=1, col=3)\n",
    "    metric_figure.show()\n",
    "\n",
    "def pcshow2(source, target, reg, reg2, err_source, err_target, err_reg, err_reg2, name,typ,setting, rotation, DefLvl):\n",
    "    cmax = np.max(np.concatenate([err_source, err_target, err_reg, err_reg2]))\n",
    "    cmid= cmax/2\n",
    "    colorscale = \"blackbody\"\n",
    "    data=[go.Scatter3d(x=source[:,0], y=source[:,1], z=source[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_source, showscale=True, colorbar = dict(title=\"Euclidean Distance [pu]\", titleside = \"right\"), colorscale = colorscale, cmin = 0,cmid = cmid, cmax = cmax), showlegend=False),\n",
    "            go.Scatter3d(x=target[:,0],y=target[:,1], z=target[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_target, colorscale = colorscale, cmin = 0,cmid = cmid, cmax = cmax), showlegend=False),\n",
    "            go.Scatter3d(x=reg[:,0], y=reg[:,1], z=reg[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_reg, colorscale = colorscale, cmin = 0,cmid = cmid, cmax = cmax), showlegend=False),\n",
    "            go.Scatter3d(x=reg2[:,0], y=reg2[:,1], z=reg2[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_reg2, colorscale = colorscale, cmin = 0,cmid = cmid, cmax = cmax), showlegend=False),\n",
    "            go.Scatter3d(x=target[:,0],y=target[:,1], z=target[:,2],\n",
    "                                   mode='markers',marker=dict(size=2,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=\"lime\", opacity=0.8), showlegend=False)]\n",
    "    fig = visualize_rotate(data)\n",
    "\n",
    "    metric_figure = make_subplots(\n",
    "        rows=2, cols=2, horizontal_spacing=0, vertical_spacing=0.05, subplot_titles=[\"a) Source\", \"b) Target\", \"c) T-TransGraphNet\", \"d) GFN\"],\n",
    "        specs=[[{\"type\":\"scene\"}, {\"type\":\"scene\"}],[{\"type\":\"scene\"}, {\"type\":\"scene\"}]])\n",
    "\n",
    "    metric_figure.append_trace(fig.data[0], row=1, col=1)\n",
    "    metric_figure.append_trace(fig.data[1], row=1, col=2)\n",
    "    metric_figure.append_trace(fig.data[2], row=2, col=1)\n",
    "    #metric_figure.append_trace(fig.data[4], row=2, col=1) #Overlay target in registration plot\n",
    "    metric_figure.append_trace(fig.data[3], row=2, col=2)\n",
    "    #metric_figure.append_trace(fig.data[4], row=2, col=2) #Overlay target in registration plot\n",
    "    \n",
    "    metric_figure.update_layout(margin = {\"b\":0,\"t\":20,\"r\":0,\"l\":0})\n",
    "    folder = f\"{cloud}/Plots/Comparison/{typ}\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    metric_figure.write_image(f\"{folder}/s{setting}_r{rotation}_d{DefLvl}_{name}.pdf\", height=500, width=600)\n",
    "    metric_figure.show()\n",
    "\n",
    "def pcshowTN(source, target, reg, reg2, name):\n",
    "    data=[go.Scatter3d(x=source[:,0], y=source[:,1], z=source[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2), color=\"#1f77b4\"),\n",
    "                                    showlegend=False),\n",
    "            go.Scatter3d(x=target[:,0],y=target[:,1], z=target[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2), color=\"#ff7f0e\"),\n",
    "                                    showlegend=False),\n",
    "            go.Scatter3d(x=reg[:,0], y=reg[:,1], z=reg[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2), color=\"#1f77b4\"),\n",
    "                                    showlegend=False),\n",
    "            go.Scatter3d(x=reg2[:,0], y=reg2[:,1], z=reg2[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2), color=\"#ff7f0e\"), \n",
    "                                    showlegend=False)]\n",
    "    fig = visualize_rotate(data)\n",
    "\n",
    "    metric_figure = make_subplots(\n",
    "        rows=2, cols=2, horizontal_spacing=0, vertical_spacing=0.05, subplot_titles=[\"a) Source\", \"b) Target\", \"c) Source after T-Net\", \"d) Target after T-Net\"],\n",
    "        specs=[[{\"type\":\"scene\"}, {\"type\":\"scene\"}],[{\"type\":\"scene\"}, {\"type\":\"scene\"}]])\n",
    "\n",
    "    metric_figure.append_trace(fig.data[0], row=1, col=1)\n",
    "    metric_figure.append_trace(fig.data[1], row=1, col=2)\n",
    "    metric_figure.append_trace(fig.data[2], row=2, col=1)\n",
    "    metric_figure.append_trace(fig.data[3], row=2, col=2)\n",
    "    \n",
    "    metric_figure.update_layout(margin = {\"b\":0,\"t\":20,\"r\":0,\"l\":0})\n",
    "    folder = f\"{cloud}/Plots/T-Net/\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    metric_figure.write_image(f\"{folder}/{name}.pdf\", height=500, width=600)\n",
    "    metric_figure.show()\n",
    "\n",
    "def pcshowTF(source, target, err_source, err_target, ps, pt, name):\n",
    "    cmax = np.max(np.concatenate([err_source, err_target]))\n",
    "    cmid= cmax/2\n",
    "    colorscale = \"blackbody\"\n",
    "    data=[go.Scatter3d(x=source[:,0], y=source[:,1], z=source[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_source, showscale=True, colorbar = dict(title=\"L2 norm\", titleside = \"right\"), colorscale = colorscale, cmin = 0,cmid = cmid, cmax = cmax), showlegend=False),\n",
    "            go.Scatter3d(x=target[:,0],y=target[:,1], z=target[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_target, colorscale = colorscale, cmin = 0,cmid = cmid, cmax = cmax), showlegend=False),\n",
    "            go.Scatter3d(x=[ps[0]], y=[ps[1]], z=[ps[2]],\n",
    "                                   mode='markers',marker=dict(size=10,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=\"lime\"), showlegend=False),\n",
    "            go.Scatter3d(x=[pt[0]], y=[pt[1]], z=[pt[2]],\n",
    "                                   mode='markers',marker=dict(size=10,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=\"lime\"), showlegend=False)]\n",
    "    fig = visualize_rotate(data)\n",
    "\n",
    "    metric_figure = make_subplots(\n",
    "        rows=1, cols=2, horizontal_spacing=0, vertical_spacing=0.05, subplot_titles=[\"a) Source\", \"b) Target\"],\n",
    "        specs=[[{\"type\":\"scene\"}, {\"type\":\"scene\"}]])\n",
    "\n",
    "    metric_figure.append_trace(fig.data[0], row=1, col=1)\n",
    "    metric_figure.append_trace(fig.data[1], row=1, col=2)\n",
    "    metric_figure.append_trace(fig.data[2], row=1, col=1)\n",
    "    metric_figure.append_trace(fig.data[3], row=1, col=2)\n",
    "    \n",
    "    metric_figure.update_layout(margin = {\"b\":0,\"t\":20,\"r\":0,\"l\":0})\n",
    "    folder = f\"{cloud}/Plots/Transformer\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    metric_figure.write_image(f\"{folder}/{name}.pdf\", height=250, width=600)\n",
    "    metric_figure.show()    \n",
    "\n",
    "def pcshowMSC(source, target, err_source, err_target, f_source, f_target, name):\n",
    "    cmax = np.max(np.concatenate([err_source, err_target]))\n",
    "    cmid= cmax/2\n",
    "    colorscale = \"blackbody\"\n",
    "    data=[go.Scatter3d(x=source[:,0], y=source[:,1], z=source[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=f_source, showscale=True, colorbar_y=0.75, colorbar_len=0.5, colorbar = dict(title=\"Mahalanobis-Euclidean [pu]\", titleside = \"right\"), colorscale = colorscale, cmin = 0,cmid = cmid, cmax = cmax), showlegend=False),\n",
    "            go.Scatter3d(x=target[:,0],y=target[:,1], z=target[:,2],\n",
    "                                   mode='markers',marker=dict(size=3,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=f_target, colorscale = colorscale, cmin = 0,cmid = cmid, cmax = cmax), showlegend=False),\n",
    "            go.Scatter3d(x=source[:,0], y=source[:,1], z=source[:,2],\n",
    "                                   mode='markers',marker=dict(size=2,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_source), showlegend=False),\n",
    "            go.Scatter3d(x=target[:,0],y=target[:,1], z=target[:,2],\n",
    "                                   mode='markers',marker=dict(size=2,\n",
    "                                    line=dict(width=2),\n",
    "                                    color=err_target), showlegend=False)]\n",
    "    fig = visualize_rotate(data)\n",
    "    metric_figure = make_subplots(\n",
    "        rows=2, cols=2, horizontal_spacing=0, vertical_spacing=0.05, subplot_titles=[\"a) Source Morse Function\",\"b) Target Morse Function\", \"c) Source Partitions\", \"d) Target Partitions\"],\n",
    "        specs=[[{\"type\":\"scene\"}, {\"type\":\"scene\"}],[{\"type\":\"scene\"}, {\"type\":\"scene\"}]])\n",
    "\n",
    "    metric_figure.append_trace(fig.data[0], row=1, col=1)\n",
    "    metric_figure.append_trace(fig.data[1], row=1, col=2)\n",
    "    metric_figure.append_trace(fig.data[2], row=2, col=1)\n",
    "    metric_figure.append_trace(fig.data[3], row=2, col=2)\n",
    "    \n",
    "    metric_figure.update_layout(margin = {\"b\":0,\"t\":20,\"r\":0,\"l\":0})\n",
    "    folder = f\"{cloud}/Plots/MSC/\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    metric_figure.write_image(f\"{folder}/{name}.pdf\", height=500, width=600)\n",
    "    metric_figure.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data and Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ModelNet\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                    PointSampler(1024),\n",
    "                    Normalize_ModelNet(),\n",
    "                    TPS(),\n",
    "                    Modify(),\n",
    "                    RandRotation_z() \n",
    "                    ])\n",
    "rotation = 1/8\n",
    "train_ds = PointCloudData_ModelNet(path, transform=train_transforms, typ=[\"Deformation_Level\",\"Incompleteness_Data\",\"Noisy_Data\",\"Outlier_Data\"], rotation=rotation)\n",
    "valid_ds = PointCloudData_ModelNet(path, folder='test', transform=train_transforms, typ=[\"Deformation_Level\",\"Incompleteness_Data\",\"Noisy_Data\",\"Outlier_Data\"],rotation=rotation) #[\"Deformation_Level\",\"Incompleteness_Data\",\"Noisy_Data\",\"Outlier_Data\"]\n",
    "\n",
    "train_loader = DataLoader(dataset=train_ds, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network\n",
    "net = TGraphNet()\n",
    "net.load_state_dict(torch.load(f'{cloud}save.pth'))\n",
    "net.to(device);\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net=net, train_loader=train_loader, val_loader=valid_loader, predictor=sLBP_GF, epochs=10, save=None, load=0, minibatches=100):\n",
    "    \"\"\"\n",
    "    IN:\n",
    "    net : torch net\n",
    "        Network to train\n",
    "    train_loader : Dataloader\n",
    "        Dataloader for training\n",
    "    val_loader : Dataloader\n",
    "        Dataloader for validation\n",
    "    predictor : func\n",
    "        Wrapper to handle Network predictions\n",
    "    epochs : int\n",
    "        Number of Epochs to train Network for\n",
    "    save : bool\n",
    "        Save runs using tensorboard and trained network .pth every epoch\n",
    "    load : int\n",
    "        To continue training. Put in, how many epochs the network has already been trained\n",
    "    minibatches : int\n",
    "        Number of samples after which to print and store loss\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize optimizer and scaler\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    # Create a SummaryWriter for TensorBoard visualization\n",
    "    if save:\n",
    "        writer = SummaryWriter(f\"{cloud}runs/{save}\")\n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(load, load + epochs):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over mini-batches in the training DataLoader\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            source, target, disp = (\n",
    "                data[\"source_pointcloud\"].to(device).float(),\n",
    "                data[\"target_pointcloud\"].to(device).float(),\n",
    "                data[\"disp\"].to(device),\n",
    "            )\n",
    "\n",
    "            # Reset optimizer gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Shuffle target point clouds\n",
    "            ind = np.arange(target.shape[1])\n",
    "            np.random.shuffle(ind)\n",
    "            target = target[:, ind, :]\n",
    "\n",
    "            # Compute displacement prediction\n",
    "            disp_pred = predictor(source, target, net)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = netloss(disp, disp_pred)\n",
    "\n",
    "            # Backpropagation and optimization step\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            # Accumulate running loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % minibatches == minibatches - 1:\n",
    "                avg_loss = running_loss / minibatches\n",
    "                print(\n",
    "                    '[Epoch: %d, Batch: %4d / %4d], loss: %.3f'\n",
    "                    % (epoch + 1, i + 1, len(train_loader), avg_loss)\n",
    "                )\n",
    "\n",
    "                # Add training loss to TensorBoard\n",
    "                if save:\n",
    "                    writer.add_scalars(\n",
    "                        \"Training Loss\",\n",
    "                        {\"Training\": avg_loss},\n",
    "                        epoch * len(train_loader) + i,\n",
    "                    )\n",
    "\n",
    "                running_loss = 0.0\n",
    "\n",
    "        net.eval()\n",
    "\n",
    "        # Save trained network and TensorBoard writer flush\n",
    "        if save:\n",
    "            if not os.path.exists(f\"{cloud}Saves/{save}\"):\n",
    "                os.makedirs(f\"{cloud}Saves/{save}\")\n",
    "            torch.save(net.state_dict(), f\"{cloud}Saves/{save}/save_{str(epoch + 1)}.pth\")\n",
    "            writer.flush()\n",
    "\n",
    "        # Perform validation if validation DataLoader is provided\n",
    "        if val_loader:\n",
    "            val_acc = 0\n",
    "            chamf_acc = 0\n",
    "            dhd_acc = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    source, target, disp = (\n",
    "                        data[\"source_pointcloud\"].to(device).float(),\n",
    "                        data[\"target_pointcloud\"].to(device).float(),\n",
    "                        data[\"disp\"].to(device),\n",
    "                    )\n",
    "\n",
    "                    # Compute displacement prediction\n",
    "                    disp_pred = predictor(source, target, net)\n",
    "\n",
    "                    # Compute registration and distance\n",
    "                    reg = source + disp_pred\n",
    "                    valid_ind = data['valid_ind'][0].to(device).long()\n",
    "                    \n",
    "                    #dist = reg - target\n",
    "\n",
    "                    # Compute mean distance, Chamfer distance, and directed Hausdorff distance\n",
    "                    val_acc += torch.mean(torch.linalg.norm((reg.squeeze() - target.squeeze()[valid_ind]), dim=1)).item()#torch.mean(torch.linalg.norm(dist.squeeze(), axis=1)).item()\n",
    "                    chamf_acc += chamfer_distance_without_batch(reg, target)\n",
    "                    dhd, _, _ = directed_hausdorff(reg.squeeze().cpu(), target.squeeze().cpu())\n",
    "                    dhd_acc += dhd\n",
    "\n",
    "            # Compute average validation metrics\n",
    "            val_acc = val_acc / len(val_loader)\n",
    "            chamf_acc = chamf_acc / len(val_loader)\n",
    "            dhd_acc = dhd_acc / len(val_loader)\n",
    "\n",
    "            # Print and add validation metrics to TensorBoard\n",
    "            print(f\"Mean dist: {val_acc}, Chamfer: {chamf_acc}, DHD: {dhd_acc}\")\n",
    "\n",
    "            if save:\n",
    "                writer.add_scalars(\n",
    "                    \"Mean distance\",\n",
    "                    {\"Valid\": val_acc},\n",
    "                    epoch * len(train_loader),\n",
    "                )\n",
    "                writer.add_scalars(\n",
    "                    \"Chamfer distance\",\n",
    "                    {\"Valid\": chamf_acc},\n",
    "                    epoch * len(train_loader),\n",
    "                )\n",
    "                writer.add_scalars(\n",
    "                    \"DHD\",\n",
    "                    {\"Valid\": dhd_acc},\n",
    "                    epoch * len(train_loader),\n",
    "                )\n",
    "                writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(save=\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_loader=valid_loader, predictor=sLBP_GF, save=None, skip=1, show=False, timer=False, net=net, net2=False, predictor2=sLBP_GF_old):\n",
    "    \"\"\"\n",
    "    IN:\n",
    "    val_loader : Dataloader\n",
    "        Dataloader for valid data to evaluate\n",
    "    predictor : func\n",
    "        Predictor function which should handle network and predict disps\n",
    "    save : string\n",
    "        Folder to store evaluation in\n",
    "    skip : int\n",
    "        Skip data if whole evaluation would take too long, not really efficient. 1 evaluates everything, 2 every second and so on\n",
    "    show : bool\n",
    "        Enable plot of registration\n",
    "    timer : bool\n",
    "        Whether to time the predictor or not\n",
    "    net : Network class \n",
    "        Network to evaluate\n",
    "    net2 : Network class\n",
    "        Second network, usually GFN as comparison for figures\n",
    "    predictor2 : func\n",
    "        Second predictor function for net2, usually baseline LBP registration with candidates from Euclidean space\n",
    "\n",
    "    Out:\n",
    "        Dataframe of evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    if val_loader:\n",
    "        results = {\"Rotation\" : [], \"Type\" : [], \"Deformation Level\" : [], \"Setting\" : [], \"Name\" : [], \"Initial Mean\" : [], \"Initial Std\":[], \"Initial Max\":[], \"Initial Chamfer\" : [], \"Initial DHD\" : [], \"Registered Mean\" : [], \"Registered Std\":[], \"Registered Max\":[], \"Registered Chamfer\" : [], \"Registered DHD\" : []}\n",
    "        with torch.no_grad():\n",
    "            s=time.time()\n",
    "            if net2:\n",
    "                counter=0\n",
    "            for i,data in enumerate(val_loader):\n",
    "                if i%skip == 0:\n",
    "                    source, target, disp = data['source_pointcloud'].to(device).float(),data['target_pointcloud'].to(device).float(), data['disp'].squeeze()\n",
    "                    typ = data['type'][0] \n",
    "                    DefLev = data['deformation'][0]\n",
    "                    setting = data['setting'][0]\n",
    "                    if not type(setting)==str:\n",
    "                        setting = setting.item()\n",
    "                    name = data['name'][0]\n",
    "                    if setting: \n",
    "                        folder= f\"Evaluation/{save}/{typ}/{setting}/{DefLev}\"\n",
    "                    else:\n",
    "                        folder= f\"Evaluation/{save}/{typ}/{DefLev}\"\n",
    "                    file = f\"{folder}/{name}.xyz\"\n",
    "                    if not os.path.exists(file):\n",
    "                        disp_pred = predictor(source, target, net)\n",
    "                    else:\n",
    "                        disp_pred = torch.from_numpy(np.loadtxt(file)).to(device)\n",
    "                    if timer:\n",
    "                        t0 = benchmark.Timer(stmt='predictor(source, target, net)',globals={'predictor': predictor, 'source' :source, 'target' :target, 'net':net})\n",
    "                        print(t0.timeit(100))\n",
    "                        #input()\n",
    "                    if net2:\n",
    "                        disp_pred2 = predictor2(source, target, net2)\n",
    "                    try: \n",
    "                        rotation = data['rotation'][0].item()\n",
    "                        print(\"Rotation:\", rotation)\n",
    "                        results[\"Rotation\"].append(rotation)\n",
    "                    except: \n",
    "                        print(\"No Rotation\")\n",
    "                        results[\"Rotation\"].append(0)\n",
    "                    \n",
    "                    reg = source + disp_pred\n",
    "\n",
    "                    valid_ind = data['valid_ind'][0].to(device).long()\n",
    "                    err= torch.linalg.norm(disp, dim=1)\n",
    "                    err_reg = torch.linalg.norm((reg.squeeze() - target.squeeze()[valid_ind]), dim=1)\n",
    "                    err_mean=torch.mean(err).item()\n",
    "                    err_std=torch.std(err).item()\n",
    "                    err_max=torch.max(err).item()\n",
    "                    err_reg_mean = torch.mean(err_reg).item()\n",
    "                    err_reg_std=torch.std(err_reg).item()\n",
    "                    err_reg_max = torch.max(err_reg).item()\n",
    "                    err= err.cpu()\n",
    "                    err_reg = err_reg.cpu()\n",
    "                    err_source = err\n",
    "                    err_target = np.zeros(target.shape[1])\n",
    "                    err_target[valid_ind.cpu()]=err\n",
    "                    chamf = chamfer_distance_without_batch(source,target[:,valid_ind]).item()\n",
    "                    chamf_reg = chamfer_distance_without_batch(reg,target[:,valid_ind]).item()\n",
    "                    target_cpu = target.squeeze()[valid_ind].cpu()\n",
    "                    dhd,_,_ = directed_hausdorff(source.squeeze().cpu(),target_cpu)\n",
    "                    dhd_reg,_,_ = directed_hausdorff(reg.squeeze().cpu(),target_cpu)\n",
    "                    if net2:\n",
    "                        reg2 = source + disp_pred2\n",
    "                        err_reg2 = torch.linalg.norm((reg2.squeeze() - target.squeeze()[valid_ind]), dim=1).cpu()\n",
    "                        err_reg_mean2=torch.mean(err_reg2).item()\n",
    "                        err_reg_std2=torch.std(err_reg2).item()\n",
    "                        if err_reg_mean <= err_reg_mean2: counter+=1\n",
    "\n",
    "                    results[\"Type\"].append(typ)\n",
    "                    results[\"Deformation Level\"].append(float(DefLev))\n",
    "                    results[\"Setting\"].append(setting)\n",
    "                    results[\"Name\"].append(name)\n",
    "                    results[\"Initial Mean\"].append(err_mean)\n",
    "                    results[\"Initial Std\"].append(err_std)\n",
    "                    results[\"Initial Max\"].append(err_max)\n",
    "                    results[\"Initial Chamfer\"].append(chamf)\n",
    "                    results[\"Initial DHD\"].append(dhd)\n",
    "                    results[\"Registered Mean\"].append(err_reg_mean)\n",
    "                    results[\"Registered Std\"].append(err_reg_std)\n",
    "                    results[\"Registered Max\"].append(err_reg_max)\n",
    "                    results[\"Registered Chamfer\"].append(chamf_reg)\n",
    "                    results[\"Registered DHD\"].append(dhd_reg)\n",
    "\n",
    "                    print(f\"Type: {typ} at {setting} \\n Deformation: {DefLev} \\n Initial: Mean: {err_mean:{1}.{5}} +/- {err_std:{1}.{5}} mm (Max: {err_max:{1}.{5}} mm), Chamfer: {chamf:{1}.{5}}, DHD: {dhd:{1}.{5}} \\n Registered: Mean: {err_reg_mean:{1}.{5}} +/- {err_reg_std:{1}.{5}} mm (Max: {err_reg_max:{1}.{5}} mm), Chamfer: {chamf_reg:{1}.{5}}, DHD: {dhd_reg:{1}.{5}}\")\n",
    "                    if net2: print(f\"Registered Net2 in d): Mean: {err_reg_mean2:{1}.{5}} +/- {err_reg_std2:{1}.{5}} mm\")\n",
    "                    \n",
    "                    if save:\n",
    "                        if setting: \n",
    "                            folder= f\"Evaluation/{save}/{typ}/{setting}/{DefLev}\"\n",
    "                        else:\n",
    "                            folder= f\"Evaluation/{save}/{typ}/{DefLev}\"\n",
    "                        if not os.path.exists(folder):\n",
    "                            os.makedirs(folder)\n",
    "                        np.savetxt(f\"{folder}/{name}.xyz\",disp_pred.squeeze().cpu().numpy())\n",
    "                    p = (i+1e-10)/len(val_loader)\n",
    "                    t = (time.time()-s)*(1/p-1)\n",
    "                    h = int(t/3600)\n",
    "                    m = int(t%3600/60)\n",
    "                    print(f\"{p*100:{2}.{4}} %, Remaining: {h}:{m}h\")\n",
    "                    if show:\n",
    "                        if net2:\n",
    "                            pcshow2(source.squeeze().cpu(), target.squeeze().cpu(), reg.squeeze().cpu(), reg2.squeeze().cpu(), err_source, err_target, err_reg, err_reg2, name,typ,setting, rotation, DefLev)\n",
    "                        else:\n",
    "                            pcshow(source.squeeze().cpu(), target.squeeze().cpu(), reg.squeeze().cpu(), err_source, err_target, err_reg)\n",
    "                        input()\n",
    "                        #time.sleep(2)  \n",
    "            if net2: print(f\"Net 1 is in {counter/len(val_loader)*100} % of cases more accurate than net 2.\")\n",
    "            df=pd.DataFrame.from_dict(results)\n",
    "            if save: \n",
    "                if not os.path.exists(f\"{cloud}Evaluation/{save}\"):\n",
    "                    os.makedirs(f\"{cloud}Evaluation/{save}\")\n",
    "                df.to_csv(f\"{cloud}Evaluation/{save}/dataframe.csv\", index=False)\n",
    "            return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ModelNet Evaluate all types for 3D visual evaluation\n",
    "_=evaluate(valid_loader, sLBP_GF, save=None, skip=15,show=1,timer=0, net2=net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ModelNet evaluate all types multiple times for statistical evaluation\n",
    "save = \"ModelNet10_TN_GFN_TF_Conv4_kf_eighthrot\"\n",
    "#save = \"ModelNet10_sLBP_GF_eighthrot\"\n",
    "df = pd.DataFrame()\n",
    "for i in range(20):\n",
    "    valid_ds = PointCloudData_ModelNet(path, folder='test', transform=train_transforms, typ=[\"Deformation_Level\",\"Incompleteness_Data\",\"Noisy_Data\",\"Outlier_Data\"],rotation=rotation)\n",
    "    valid_loader = DataLoader(dataset=valid_ds, batch_size=1)\n",
    "    dfi=evaluate(valid_loader, sLBP_GF, save=None, skip=1,show=0,timer=0, net=net)\n",
    "    df = pd.concat([df,dfi], ignore_index=True)\n",
    "if not os.path.exists(f\"{cloud}Evaluation/{save}\"):\n",
    "        os.makedirs(f\"{cloud}Evaluation/{save}\")\n",
    "df.to_csv(f\"{cloud}Evaluation/{save}/dataframeGaussFine.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to combine dataframes if needed\n",
    "save= \"ModelNet10_sLBP_GF_kf_eighthrot\"\n",
    "df1= pd.read_csv(f\"{cloud}/Evaluation/{save}/dataframe.csv\")\n",
    "df2= pd.read_csv(f\"{cloud}/Evaluation/{save}/dataframe2.csv\")\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df.to_csv(f\"{cloud}Evaluation/{save}/dataframeCombined.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotevaltwo(df, data, ylabel, net_names, size=14, filter=None):\n",
    "    y = [\"Registered Mean\", \"Initial Mean\"]\n",
    "    if filter:\n",
    "        title = f\"{filter[0]} {filter[1]} {data} {y}\"\n",
    "    else:\n",
    "        title = f\"{data} {y}\"\n",
    "\n",
    "    fig = go.Figure()\n",
    "    if data == 'Incompleteness_Data':\n",
    "        legend_title = \"Incompleteness in %\"\n",
    "        group='Setting'\n",
    "    elif data == \"Outlier_Data\":\n",
    "        legend_title = 'Outlier in %'\n",
    "        group='Setting'\n",
    "    elif data == \"Deformation_Level\":\n",
    "        legend_title = 'Deformation Level'\n",
    "        group='Deformation Level'\n",
    "    elif data == \"Rotation\":\n",
    "        legend_title = 'Rotation [rad]'\n",
    "        group = data\n",
    "        data = \"Deformation_Level\"\n",
    "    else:\n",
    "        legend_title = 'Noise Standard Deviation'\n",
    "        group='Setting'\n",
    "    dfd=df[0][df[0]['Type']==data]\n",
    "    if filter:\n",
    "        dfd = dfd[dfd[filter[0]] == filter[1]]\n",
    "    dfd2 = df[1][df[1]['Type']==data]\n",
    "    if filter:\n",
    "        dfd2=dfd2[dfd2[filter[0]] == filter[1]]\n",
    "    c=np.unique(dfd2[group].to_numpy())\n",
    "    net0=[]\n",
    "    net1=[]\n",
    "    init=[]\n",
    "    net0_std_l=[]\n",
    "    net1_std_l=[]\n",
    "    init_std_l=[]\n",
    "    net0_std_r=[]\n",
    "    net1_std_r=[]\n",
    "    init_std_r=[]\n",
    "    for i in c:      \n",
    "        init_mean = dfd[dfd[group]==i][\"Initial Mean\"].to_numpy()\n",
    "        i_l,i_r = bootstrap((init_mean,), np.mean, confidence_level=0.997, vectorized=False).confidence_interval\n",
    "        init_std_l.append(i_l)\n",
    "        init_std_r.append(i_r)\n",
    "        init.append(np.mean(init_mean))\n",
    "        net0_mean = dfd[dfd[group]==i][\"Registered Mean\"].to_numpy()\n",
    "        n0_l,n0_r = bootstrap((net0_mean,), np.mean, confidence_level=0.997, vectorized=False).confidence_interval\n",
    "        net0_std_l.append(n0_l)\n",
    "        net0_std_r.append(n0_r)\n",
    "        net0.append(np.mean(net0_mean))\n",
    "        net1_mean = dfd2[dfd2[group]==i][\"Registered Mean\"].to_numpy()\n",
    "        n1_l,n1_r = bootstrap((net1_mean,), np.mean, confidence_level=0.997, vectorized=False).confidence_interval\n",
    "        net1_std_l.append(n1_l)\n",
    "        net1_std_r.append(n1_r)\n",
    "        net1.append(np.mean(net1_mean))\n",
    "    offset=np.max(c)*0.005\n",
    "    fig.update_xaxes(range=[np.min(c)-offset,np.max(c)+offset])\n",
    "    max_y_std = np.max(init_std_r)\n",
    "    max_y_mean = np.max(init)\n",
    "    max_y = max_y_std + max_y_mean\n",
    "    fig.update_yaxes(range=[0,max_y*(1.005)])\n",
    "    fig.add_trace(go.Scatter(x=c, y=init,error_y=dict(array=init_std_r, arrayminus=init_std_l), cliponaxis=True,\n",
    "                    mode='lines+markers',\n",
    "                    name=\"Source\"))\n",
    "    fig.add_trace(go.Scatter(x=c, y=net1, error_y=dict(array=net1_std_r, arrayminus=net1_std_l), cliponaxis=True,\n",
    "                    mode='lines+markers',\n",
    "                    name=f\"Registered {net_names[1]}\"))\n",
    "    fig.add_trace(go.Scatter(x=c, y=net0, error_y=dict(array=net0_std_r, arrayminus=net0_std_l), cliponaxis=True,\n",
    "                    mode='lines+markers',\n",
    "                    name=f\"Registered {net_names[0]}\"))\n",
    "    fig.update_layout(yaxis_title=ylabel,\n",
    "                        xaxis_title = legend_title,\n",
    "                        legend=dict(\n",
    "                                title=\"Distance target to\",\n",
    "                            ),\n",
    "                        margin = {\"b\":0,\"t\":0,\"r\":0,\"l\":0},\n",
    "                        font_size = size\n",
    "                        )\n",
    "    if not os.path.exists(f\"{cloud}Plots/{net_names}\"):\n",
    "        os.makedirs(f\"{cloud}Plots/{net_names}\")\n",
    "    fig.write_image(f\"{cloud}/Plots/{net_names}/{title}.pdf\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"ModelNet10_TN_GFN_TF_Conv4_kf_eighthrot_AllChallenges_save5\"\n",
    "model2 = \"ModelNet10_sLBP_GF_eighthrot_AllChallenges\"\n",
    "df = pd.read_csv(f\"{cloud}/Evaluation/{model}/dataframeGaussFineBig.csv\")\n",
    "df2 = pd.read_csv(f\"{cloud}/Evaluation/{model2}/dataframeGaussFineBig.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in [\"Deformation_Level\",\"Incompleteness_Data\",\"Noisy_Data\",\"Outlier_Data\",\"Rotation\"]: #[\"Rotation\",\"Deformation_Level\",\"Incompleteness_Data\",\"Noisy_Data\",\"Outlier_Data\"]\n",
    "    plotevaltwo([df,df2], s, \"Mean Euclidean Distance [pu]\", [\"T-TransGraphNet\", \"GFN\"])#, filter=[\"Deformation Level\", 0.1]) #, filter=[\"Rotation\", 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotloss(kind, yaxis):\n",
    "    fig = go.Figure()\n",
    "    if kind == \"Mean\": \n",
    "        fig.update_xaxes(range=[0, 36000])\n",
    "        mode = 'lines+markers'\n",
    "    else:\n",
    "        mode = 'lines'\n",
    "    for i,file in enumerate(glob.glob(f\"{cloud}/RunsCSV/{kind}/*.csv\")):\n",
    "        name=Path(file).stem[1:]#\"_\".join(Path(file).stem.split(sep = \"_\")[1:-2])\n",
    "        data = np.loadtxt(file, skiprows = 1, delimiter=\",\")\n",
    "        if i == 0:\n",
    "            j = data.shape[0]\n",
    "        fig.add_trace(go.Scatter(x=data[:j,1], y=data[:j,2], cliponaxis=True,\n",
    "                    mode=mode,\n",
    "                    name=name))\n",
    "    fig.update_layout(#title=title,\n",
    "                    xaxis_title='Step',\n",
    "                    yaxis_title=yaxis,\n",
    "                    legend=dict(\n",
    "                            yanchor=\"top\",\n",
    "                            y=0.99,\n",
    "                            xanchor=\"right\",\n",
    "                            x=0.99\n",
    "                        ),\n",
    "                    margin = {\"b\":0,\"t\":0,\"r\":0,\"l\":0})\n",
    "    fig.write_image(f\"{cloud}/Plots/{kind}.pdf\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotloss(\"Mean\", 'Validation Loss (L2) [pu]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotloss(\"Loss\", 'Training Loss (L2) [pu]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PointNetPytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "677d55c36af68aea971a73ad48b185ea9dab5369d74b431e895c5e681580ada6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
